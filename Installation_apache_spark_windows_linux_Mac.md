
## Installation de Apache Spark en Local

### Installer Spark sous Windows
    Lien de référence:
                            https://phoenixnap.com/kb/install-spark-on-windows-10
                            
### Installer Spark sous Linux (Ubuntu) 
    Lien de référence:
                            https://phoenixnap.com/kb/install-spark-on-ubuntu
                            
### Installer Spark sous Mac
    Lien de référence:
                            https://www.freecodecamp.org/news/installing-scala-and-apache-spark-on-mac-os-837ae57d283f/



## Utiliser la plateforme DataBricks

        1- Créer un compte :  
                 * https://community.cloud.databricks.com/login.html, cliquer sur "Sign Up" puis créer un compte
                 * Dans la partie 'Choose a cloud provider', un peu plus en bas, cliquer sur 'Get started with Community Edition'
                 * Connectez-vous à votre compte gmail pour valider l'inscription en cliquant sur 'this link'
                 * Choisissez un mot de passe, puis valider
                 * Et Youpiiii, vous êtes dans votre plateforme databricks community
        
        2- Création d'un cluster : 
                * Sur le panel droit, cliquer sur l'icone avec la description "Clusters"
                * Cliquer sur "Create Cluster"
                * Donner un nom au cluster puis cliquer sur "Create Cluster"
                
        3- Importation d'un notebook :               
                * Tout d'abord télécharger les fichiers dans un répertoiore de votre choix
                * Dans la plateforme Databricks, sur le panel droiot, cliquer sur "Workspace"
                * Dérouler l'option "Shared", puis choisissez "Import"
                * Cliquer sur Browser et choisissez le fichier à importer puis Importer
                
